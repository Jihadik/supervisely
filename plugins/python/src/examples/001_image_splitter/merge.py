import supervisely_lib as sly
from collections import defaultdict
import numpy as np

WORKSPACE_ID = int('%%WORKSPACE_ID%%')
src_project_name = '%%IN_PROJECT_NAME%%'
dst_project_name = '%%RESULT_PROJECT_NAME%%'

# for debug
# WORKSPACE_ID = 27
# src_project_name = "change_size2"#"shift_window"#"add_padding"
# dst_project_name = "change_size2 [merged]"#"shift_window [merged]"#"add_padding [merged]"


api = sly.Api.from_env()

workspace = api.workspace.get_info_by_id(WORKSPACE_ID)
if workspace is None:
    raise RuntimeError("Workspace with ID={!r} not found".format(WORKSPACE_ID))

src_project = api.project.get_info_by_name(workspace.id, src_project_name)
if src_project is None:
    raise RuntimeError("Project with name={!r} not found".format(src_project_name))

meta_json = api.project.get_meta(src_project.id)
meta = sly.ProjectMeta.from_json(meta_json)

dst_project = api.project.create(workspace.id, dst_project_name, change_name_if_conflict=True)
if dst_project.name != dst_project_name:
    sly.logger.warn("Project with name={!r} already exists. Project is saved with autogenerated name {!r}"
                    .format(dst_project_name, dst_project.name))
api.project.update_meta(dst_project.id, meta.to_json())

progress = sly.Progress("Merging images", api.project.get_images_count(src_project.id))
for src_dataset in api.dataset.get_list(src_project.id):
    dst_dataset = api.dataset.create(dst_project.id, src_dataset.name)
    images = api.image.get_list(src_dataset.id)
    image_ids = [image_info.id for image_info in images]
    image_names = [image_info.name for image_info in images]

    ann_infos = api.annotation.download_batch(src_dataset.id, image_ids)
    anns = [sly.Annotation.from_json(ann_info.annotation, meta) for ann_info in ann_infos]

    parts_ids = defaultdict(list)
    parts_top_left = defaultdict(list)
    parts_anns = defaultdict(list)

    max_height = defaultdict(int)
    max_width = defaultdict(int)
    for image_info, ann in zip(images, anns):
        real_name = image_info.name.split("___")[0]
        ext = sly.fs.get_file_ext(image_info.name)
        settings = image_info.name.split("___")[1]
        settings = settings.replace(ext, "")

        window_index = int(settings.split("_")[0])
        window_top = int(settings.split("_")[1])
        window_left = int(settings.split("_")[2])

        original_name = "{}{}".format(real_name, ext)

        max_height[original_name] = max(max_height[original_name], window_top + ann.img_size[0])
        max_width[original_name] = max(max_width[original_name], window_left + ann.img_size[1])
        parts_ids[original_name].append(image_info.id)
        parts_top_left[original_name].append((window_top, window_left))
        parts_anns[original_name].append(ann)

    for original_name in parts_ids.keys():
        images = api.image.download_nps(src_dataset.id, parts_ids[original_name])
        height = max_height[original_name]
        width = max_width[original_name]
        channels = images[0].shape[2]
        final_image = np.zeros((height, width, channels), dtype=np.uint8)
        final_ann = sly.Annotation(final_image.shape[:2])
        for image_part, ann, (top, left) in zip(images, parts_anns[original_name], parts_top_left[original_name]):
            def _translate_label(label):
                shift_y = top
                shift_x = left
                return [label.translate(shift_y, shift_x)]
            ann = ann.transform_labels(_translate_label, new_size=final_image.shape[:2])
            final_image[top:top+image_part.shape[0], left:left+image_part.shape[1], :] = image_part
            final_ann = final_ann.add_labels(ann.labels)
            final_ann = final_ann.clone(img_tags=final_ann.img_tags.merge_without_duplicates(ann.img_tags))
        merged_image_info = api.image.upload_np(dst_dataset.id, original_name, final_image)
        api.annotation.upload_ann(merged_image_info.id, final_ann)

sly.logger.info('PROJECT_CREATED', extra={'event_type': sly.EventType.PROJECT_CREATED, 'project_id': dst_project.id})